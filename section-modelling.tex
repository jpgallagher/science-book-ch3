\nopagebreak
\section{Energy Modelling}\label{sec:energy-models}

An energy model provides information on the energy consumed when running a program on a given hardware platform, based on parameters that characterise the program and its execution. The energy model contains measured energy consumption costs for these parameters and links these costs with program specific values for the parameters to arrive at an overall energy consumption estimation. 

Models that support software energy analysis typically associate program constructs, such as source code blocks, basic blocks in the intermediate representation of the program used during compilation or machine code instructions, with energy consumption costs. In addition, other costs arising from the execution of a program may need to be considered, depending on the micro architectural features of the hardware; examples are costs associated with the memory hierarchy, such as the cost of a cache hit and miss or the cost of accessing on-chip and off-chip memory, and also costs associated with the processor pipeline, such as the cost of pipeline stalls. In addition, the cost of the processor being idle and the cost of processing multiple threads concurrently may also need to be considered. 
%
In general, to instantiate an energy model, model parameters can be obtained either from analyzing execution or simulation traces, e.g.\ counting instructions, cache hits and misses, etc, or through static analysis as will be discussed next, in Section~\ref{sec:energy-analysis}.

The challenge in energy modelling for software energy analysis is in finding a good compromise between the accuracy of the model and the ease with which the information can be mapped onto software constructs. Regarding the former, model accuracy tends to be higher for models at the lower-levels of abstraction, i.e.\ instruction-level energy models are typically more accurate than energy models at the intermediate representation of the compiler, and source code energy models are less accurate in comparison. 
%
However, understanding which source code lines or blocks consume most energy is much more useful to software developers looking to optimise their code for energy efficiency, than knowing the energy consumed by the sequence of machine instructions issued by the compiler. The higher the level of abstraction at which the information is presented to the software developer, the easier it is for them to comprehend the impact of algorithms and coding on the energy consumed during program execution. Yet, taking measurements to characterize energy models is simplest and most accurate when performed at the lower levels of abstraction, where energy costs of low-level software constructs such as machine instructions can be determined directly.



\subsection{Defining and constructing an energy model at ISA level}

The Instruction Set Architecture (ISA) is a practical level of abstraction for energy
modelling, because it directly correlates underlying hardware operations associated with instruction execution to low-level software constructs. The ISA is the interface between hardware and software. It defines the hardware architecture and its behaviour in terms of low-level programming constructs such as supported data types, machine instructions, registers, the memory architecture, any interrupt and exception handling as well as I/O operations. 

Constructing a model at this level gives us the following benefits: energy
costs can be assigned at the instruction level; the same level as is output by
the compiler; there are strong correlations between instruction properties and
energy consumption, for example the number of operands used in the instruction;
and machine instructions can be related back to the original programming
statements written by the software developer, as well as to various
intermediate representations. 

Energy modelling at ISA level dates back to 1994 when Tiwari et
al.~\cite{Tiwari-embedded-1994} first proposed a
generic method to develop instruction-level power models for arbitrary
processor architectures to estimate the power consumption caused by software.
Such models could overcome the limitations of hardware design power analysis
methods; they require access to circuit or gate level design information
including layout and tend to be impractically slow at producing results for
system-level power analysis. Instruction-level power models, instead, are
orders of magnitude faster at estimating the power consumption of embedded
software and can achieve accuracy within 10\% of what hardware design power
analysis methods deliver. This is a worthwhile tradeoff because software
development involves numerous iterations during the coding phase, and rapid
feedback of resource usage is critical for software developers to make energy
aware decisions.

The original instruction-level power model by Tiwari et al.\ as given in~\cite{TiwariWolfeInstructionLevelPowerAnalysi:1996} is summarized in Equation~\ref{e:tiwari}.

\begin{equation}\label{e:tiwari}
E_P = \sum_i (B_i \times N_i) + \sum_{i,j} (O_{i,j} \times N_{i,j}) + \sum_k E_k
\end{equation}

According to~\ref{e:tiwari}, the energy consumption of a program, $E_P$, is calculated as the sum of three components: the base cost per instruction, the cost of switching between subsequent instructions, also called the inter-instruction overhead or the circuit state overhead, and external effects within the architecture.
%
The first term in the sum in~\ref{e:tiwari} is the base cost, where $B_i$ is the base cost of instruction $i$ multiplied with the number of times $i$ occurs in $P$, $N_i$.
%
The second term is the inter-instruction overhead; $O_{i,j}$ represents the cost incurred by switching the circuit state of the processor from executing instruction $i$ to executing instruction $j$ and is multiplied by the number of times instruction $i$ is followed by instruction $j$ in $P$. This inter-instruction overhead represents the energy consumed due to switching on busses, e.g.\ as a consequence of changing op-codes and operand values, and using different functional units within the processor. 
%
Finally, the third term in the sum accounts for the cost of $k$ external effects that may impact on software related energy consumption, e.g.\ cache misses or pipeline stalls that can be characterized using external cache models or models of the micro architecture of the processor. 

Recently, instruction-level energy models have been developed for modern processors such as the Intel Xeon Phi, a many integrated core architecture for high-performance computing, and the hardware multi-threaded XMOS XCore embedded microprocessor.\todo{add references to both architectures}

The XMOS XCore instruction-level energy
model~\cite{DBLP:journals/tecs/KerrisonE15} is based on the original model by
Tiwari et al. However, it re-defines the notion of base cost to be the power dissipated
while the processor is idle, and  uses individual instruction costs, scaled by
the level of concurrency in the processor's pipeline as well as a constant overhead to
account for circuit state switching between instructions.
%
Model characterization was performed using a measurement setup and instruction
loops similar to those originally proposed in~\cite{Tiwari-embedded-1994}. The
individual instruction costs represent averages over measurements obtained from
running loops with instructions using operands that were generated
pseudo-randomly, constraining values to those valid for the respective
instruction.
%
Evaluation of this multi-threaded instruction-level model showed average error
margins of less than 7\% when used with instruction stream simulation to
instantiate the model parameters.
%
However, the model was designed to be used for static energy consumption analysis,
requiring static analysis techniques to determine the number of idle cycles and
the level of concurrent thread activity, in addition to the standard
instruction stream statistics.

In contrast, the Xeon Phi instruction-level energy model~\cite{phimodel} relies
on performance counter statistics that are obtained at runtime, rather than
through static analysis at compile time. This model is designed to be used with
software profiling tools to support energy efficient software development. The
model is built by characterising the Energy per Instruction (EPI) of selected
instruction types using microbenchmarks executed on different processor
configurations in terms of numbers of cores and threads per core. Instructions are classified in terms of op-code and operand locations, both of which influence the EPI.
%
The energy consumption of a given workload can then be determined by
multiplying the runtime instruction statistics with the respective EPIs.
%
This model achieves an average error rate of less than 5\%.




The construction of an energy model at the ISA level has to address several
challenges.
%
Measurements need to be taken to determine both the base cost for each
instruction and also the switching cost between instructions. To achieve this,
instructions are placed into infinite loops, e.g.\ loops of a single
instruction to obtain that instruction's base costs. The average power is
measured while the loop is executed. Care needs to be taken to ensure the loop
runs for a sufficiently long time to minimize measurement errors due to loop
overheads. 
%
To reduce the measurement effort, rather than determining a base cost for each instruction and individual instruction pairs, it may be sufficient to identify instruction types and determine base costs and switching costs with respect to these. 
%
However, not all instructions or instruction types can be directly profiled,
requiring indirect or statistical approaches to their characterisation. 
%
In addition, other properties such as the cost of running multiple threads and
the cost of idle periods must be determined for multi-threaded architectures, and communication costs must be considered for interacting multi-threaded programs running on multi-core platforms. 

\todo[inline]{lead over to linking energy consumption directly to higher levels - intuitive for software developers at the cost of accuracy of the predictions }

\subsection{Energy modelling at higher levels of software abstraction}
\label{subsec:mapping}

Modelling at the level of the Intermediate Representation (IR) 
used by compilers can be a useful compromise between the accuracy of a lower-level (ISA) 
model and the to high-level source code. Since the compiler is a natural
place for optimisations, modelling and predicting the energy consumption at
IR level could therefore enable energy specific optimisations.

Using a mapping technique, 
the energy model at the ISA level can be lifted to the LLVM IR level, allowing energy
consumption estimation of programs at that level. 
The mapping technique determines the energy characteristics of LLVM IR
instructions. It provides on-the-fly energy characterization that takes into
consideration the context of instructions since there is no program-independent mapping between
ISA instructions and LLVM instructions.

In principle, the same mapping technique may be used to map the energy consumption
of programs to even higher levels, such as the source code. 


An alternative approach to building a source-level energy model is to identify
basic energy-consuming operations from the source code and
correlate them to energy costs by measuring energy consumption in
a large number of test cases and analyzing the results using techniques
based on regression analysis. The resulting energy model of the basic
operations implicitly includes the effect of all the layers of the software
stack down to the hardware, including compiled code, virtual machine and operating
system layers. The approach is inherently approximate;
nevertheless such an approach may be the only feasible one in cases where the software
stack has many complex layers. 


\subsection{The impact of data on energy consumption of software}

- include the AND graph to illustrate different energy for different operands

- refer back to Tiwari 1994 where it was noted that measurements differed from predictions due to the fact that the actual operands of instructions are only known at runtime, so averages must be used for model characterization

- quote WCEC papers on data impact observed in practice

- quote our work on WCEM and WCEM-theory

- single-value energy models: WC vs average

- need for tight but safe bounds

- statistic approaches need to be developed?

\subsection{Summary}

- pros and cons of energy modelling

- important characteristics of an energy model to support EE SWE

- need for timing and energy predictability

R.Wilhelm: Timing predictability of a hw/sw system is the degree to which bounds can be determined with acceptable precision, with acceptable effort and with acceptable loss of (average-case) performance. 
